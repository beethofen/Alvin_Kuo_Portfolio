{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14sqjnsA8AFP",
      "metadata": {
        "id": "14sqjnsA8AFP"
      },
      "source": [
        "# **0. Hackathon 101 - How to Prepare Libraries Efficiently** \n",
        "\n",
        "1. \"Pyforest\" In One Line of Code\n",
        "\n",
        "  * Magic one line of code\n",
        "  * Import pyforest\n",
        "  * Test if pyforest works\n",
        "  * See 115 key import in directory\n",
        "  * Save big time from here\n",
        "\n",
        "2. Prep Your Customized Library Block\n",
        "3. Import Libraries On Demand\n",
        "4. Bottomline\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tjBzPKoG9JP_",
      "metadata": {
        "id": "tjBzPKoG9JP_"
      },
      "source": [
        "## **1. \"Pyforest\" In One Line of Code**\n",
        "\n",
        "**Pro** - There's a very efficient way to utilize just one magical line of code to make it work. Then you only need to import one instead of many (or a lot of) libraries.\n",
        "\n",
        "**Con** - Yes, it's claimed 99% of the daily work would be covered here. If you are anxious about something important for you could be missing, you have to check the 115 items if they are in or not - still taking some time. And you may have other preference of the naming than the default, too!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   **1) Code \"pip install pyforest\"**\n",
        "**What is \"pip\"** -\"preferred installer program\" - a package management system used to install and manage software packages written in Python\n",
        "\n",
        "**What is \"pyforest\"** - Python library forest? - Pretty close. If every library is like a tree, then you have a forest of the libraries so here we call it \"pyforest\""
      ],
      "metadata": {
        "id": "tYOx175b9bR2"
      },
      "id": "tYOx175b9bR2"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyforest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofmJgQOo5EsU",
        "outputId": "0b6ee11d-55f9-4df7-e93c-8cc88c239906"
      },
      "id": "ofmJgQOo5EsU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyforest in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just one line of code? Yes, it indicates this pacage has been installed with the path above. (For some reason, the first link shows up after \"Looking in indexes\" feeds me a lot of \"not-that-simple\" info. And the 2nd link did not lead me to effective content).\n",
        "But don't worry, the magic one line of code has been effective. Let's move on!"
      ],
      "metadata": {
        "id": "IMA4jViz-unm"
      },
      "id": "IMA4jViz-unm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   **2) Import pyforest**\n",
        "What's next? You could start to \"expereince\" it test something as below"
      ],
      "metadata": {
        "id": "OWntAWOS_TcA"
      },
      "id": "OWntAWOS_TcA"
    },
    {
      "cell_type": "code",
      "source": [
        "import pyforest"
      ],
      "metadata": {
        "id": "QELuJL9p6zUq"
      },
      "id": "QELuJL9p6zUq",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, at this moment, you've completed that one small step but an important big step in your Hackathon"
      ],
      "metadata": {
        "id": "F1NbNqfkA5Yg"
      },
      "id": "F1NbNqfkA5Yg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   **3) Test if pyforest works**\n",
        "What's next? You could start to \"expereince\" it test something as below\n",
        "\n",
        "####**drive.mount('/content/drive')**"
      ],
      "metadata": {
        "id": "MkLhR1jhA1eQ"
      },
      "id": "MkLhR1jhA1eQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# if you use google colab**\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtdiBRAm_ndp",
        "outputId": "2a0ac4b4-5df2-4045-d8e1-21877b2cf697"
      },
      "id": "QtdiBRAm_ndp",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, if you remount, it's ok, too."
      ],
      "metadata": {
        "id": "dKJPfQXrArli"
      },
      "id": "dKJPfQXrArli"
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Pandas to read csv**\n",
        "\n"
      ],
      "metadata": {
        "id": "yEnxSy0pCbpn"
      },
      "id": "yEnxSy0pCbpn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Pandas to read csv file is a very common starting step\n",
        "df = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ctN3DLIlABi-",
        "outputId": "5e0cca9f-a4f9-4c04-eb1d-a65470f39542"
      },
      "id": "ctN3DLIlABi-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport pandas as pd\\nfrom sklearn.model_selection import cross_val_score'); }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, if right file in your path chosen, nothing error, you could go ahead to test all the normal first step of data clearing to check the head and info."
      ],
      "metadata": {
        "id": "c4PfQmNtDPOq"
      },
      "id": "c4PfQmNtDPOq"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kTDRWVcIAR4P",
        "outputId": "72383e4a-8e4f-404d-f804-349c0e1f04dc"
      },
      "id": "kTDRWVcIAR4P",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.05     37.37                27.0       3885.0           661.0   \n",
              "1    -118.30     34.26                43.0       1510.0           310.0   \n",
              "2    -117.81     33.78                27.0       3589.0           507.0   \n",
              "3    -118.36     33.82                28.0         67.0            15.0   \n",
              "4    -119.67     36.33                19.0       1241.0           244.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1537.0       606.0         6.6085            344700.0  \n",
              "1       809.0       277.0         3.5990            176500.0  \n",
              "2      1484.0       495.0         5.7934            270500.0  \n",
              "3        49.0        11.0         6.1359            330000.0  \n",
              "4       850.0       237.0         2.9375             81700.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-579f4bd2-b2d1-488b-9746-3a5064ab2f55\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>6.6085</td>\n",
              "      <td>344700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>3.5990</td>\n",
              "      <td>176500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>5.7934</td>\n",
              "      <td>270500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>330000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>2.9375</td>\n",
              "      <td>81700.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-579f4bd2-b2d1-488b-9746-3a5064ab2f55')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-579f4bd2-b2d1-488b-9746-3a5064ab2f55 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-579f4bd2-b2d1-488b-9746-3a5064ab2f55');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cvtZG_pDieI",
        "outputId": "65283961-ffd7-4502-80b7-3f6357a833c1"
      },
      "id": "7cvtZG_pDieI",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -122.05     37.37                27.0       3885.0           661.0   \n",
              "1       -118.30     34.26                43.0       1510.0           310.0   \n",
              "2       -117.81     33.78                27.0       3589.0           507.0   \n",
              "3       -118.36     33.82                28.0         67.0            15.0   \n",
              "4       -119.67     36.33                19.0       1241.0           244.0   \n",
              "...         ...       ...                 ...          ...             ...   \n",
              "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
              "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
              "2997    -119.70     36.30                10.0        956.0           201.0   \n",
              "2998    -117.12     34.10                40.0         96.0            14.0   \n",
              "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
              "\n",
              "      population  households  median_income  median_house_value  \n",
              "0         1537.0       606.0         6.6085            344700.0  \n",
              "1          809.0       277.0         3.5990            176500.0  \n",
              "2         1484.0       495.0         5.7934            270500.0  \n",
              "3           49.0        11.0         6.1359            330000.0  \n",
              "4          850.0       237.0         2.9375             81700.0  \n",
              "...          ...         ...            ...                 ...  \n",
              "2995      1258.0       607.0         1.1790            225000.0  \n",
              "2996      3496.0      1036.0         3.3906            237200.0  \n",
              "2997       693.0       220.0         2.2895             62000.0  \n",
              "2998        46.0        14.0         3.2708            162500.0  \n",
              "2999       753.0       260.0         8.5608            500001.0  \n",
              "\n",
              "[3000 rows x 9 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9e2FHQm_D5W-",
        "outputId": "60b36bd5-9b5e-4643-ca45-db1a119d4a9f"
      },
      "id": "9e2FHQm_D5W-",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4) Use \"dir(pyforest)\" to see 115 key import in directory**\n",
        "How many libraries (and function) have been included with this one line code? 115!!! All the popular one like Pandas as \"pd\", NumPy as \"np\", Scikit-learn as \"sklearn\", you name it! "
      ],
      "metadata": {
        "id": "yUbRJQ4iEZje"
      },
      "id": "yUbRJQ4iEZje"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 115 import codes below\n",
        "dir(pyforest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3gJPahk6JIO",
        "outputId": "a0c31cb6-1273-4c43-da8e-0930602d8bc3"
      },
      "id": "e3gJPahk6JIO",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ARIMA',\n",
              " 'CountVectorizer',\n",
              " 'ElasticNet',\n",
              " 'ElasticNetCV',\n",
              " 'GradientBoostingClassifier',\n",
              " 'GradientBoostingRegressor',\n",
              " 'GridSearchCV',\n",
              " 'Image',\n",
              " 'KFold',\n",
              " 'KMeans',\n",
              " 'LabelEncoder',\n",
              " 'Lasso',\n",
              " 'LassoCV',\n",
              " 'LazyImport',\n",
              " 'LinearRegression',\n",
              " 'LogisticRegression',\n",
              " 'MinMaxScaler',\n",
              " 'OneHotEncoder',\n",
              " 'PCA',\n",
              " 'Path',\n",
              " 'PolynomialFeatures',\n",
              " 'Prophet',\n",
              " 'RandomForestClassifier',\n",
              " 'RandomForestRegressor',\n",
              " 'RandomizedSearchCV',\n",
              " 'Ridge',\n",
              " 'RidgeCV',\n",
              " 'RobustScaler',\n",
              " 'SimpleImputer',\n",
              " 'SparkContext',\n",
              " 'StandardScaler',\n",
              " 'StratifiedKFold',\n",
              " 'TSNE',\n",
              " 'TfidfVectorizer',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_importable',\n",
              " '_imports',\n",
              " '_jupyter_labextension_paths',\n",
              " '_jupyter_nbextension_paths',\n",
              " 'active_imports',\n",
              " 'alt',\n",
              " 'bokeh',\n",
              " 'cross_val_score',\n",
              " 'cv2',\n",
              " 'dash',\n",
              " 'dd',\n",
              " 'dt',\n",
              " 'fastai',\n",
              " 'fbprophet',\n",
              " 'gensim',\n",
              " 'get_user_symbols',\n",
              " 'glob',\n",
              " 'go',\n",
              " 'import_symbol',\n",
              " 'imutils',\n",
              " 'install_extensions',\n",
              " 'install_labextension',\n",
              " 'install_nbextension',\n",
              " 'keras',\n",
              " 'lazy_imports',\n",
              " 'lgb',\n",
              " 'load_workbook',\n",
              " 'metrics',\n",
              " 'mpl',\n",
              " 'nltk',\n",
              " 'np',\n",
              " 'open_workbook',\n",
              " 'os',\n",
              " 'pd',\n",
              " 'pickle',\n",
              " 'plt',\n",
              " 'px',\n",
              " 'py',\n",
              " 'pydot',\n",
              " 'pyforest_imports',\n",
              " 're',\n",
              " 'sg',\n",
              " 'skimage',\n",
              " 'sklearn',\n",
              " 'sm',\n",
              " 'sns',\n",
              " 'spacy',\n",
              " 'statistics',\n",
              " 'stats',\n",
              " 'svm',\n",
              " 'sys',\n",
              " 'textblob',\n",
              " 'tf',\n",
              " 'torch',\n",
              " 'tqdm',\n",
              " 'train_test_split',\n",
              " 'user_specific_imports',\n",
              " 'user_symbols',\n",
              " 'utils',\n",
              " 'wr',\n",
              " 'xgb']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5) Save Big Time Efficiently From Here**"
      ],
      "metadata": {
        "id": "fQ5e4zOS5IwP"
      },
      "id": "fQ5e4zOS5IwP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's summarize what you have here\n",
        "\n",
        "####**Top 4 Frequently-used Libraries**\n"
      ],
      "metadata": {
        "id": "tUuLV9_NIBmb"
      },
      "id": "tUuLV9_NIBmb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save coding below:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Y_KbrRFlHRfz"
      },
      "id": "Y_KbrRFlHRfz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It covers the most frequenty used 4 libraries to maniulate the array (numpy), DataFrame (pandas) and visualization (matplotlib.pyplot and seaborn)."
      ],
      "metadata": {
        "id": "1HUREcMCQcfX"
      },
      "id": "1HUREcMCQcfX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Frequently-used Classifier & Regressor**"
      ],
      "metadata": {
        "id": "47HgUkRKIXk3"
      },
      "id": "47HgUkRKIXk3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save coding below:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "PolynomialFeatures"
      ],
      "metadata": {
        "id": "pTGox-AeIjRG"
      },
      "id": "pTGox-AeIjRG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Cross-Validation (CV)**"
      ],
      "metadata": {
        "id": "JfgvPJ0MLEV2"
      },
      "id": "JfgvPJ0MLEV2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save coding below:\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import RidgeCV\n"
      ],
      "metadata": {
        "id": "Yu53TJ3MLKI0"
      },
      "id": "Yu53TJ3MLKI0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Scaler**"
      ],
      "metadata": {
        "id": "HRJpidJyMmgn"
      },
      "id": "HRJpidJyMmgn"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Standardcaler\n",
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "id": "NOTNrzdWNCbh"
      },
      "id": "NOTNrzdWNCbh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Vectorizer**"
      ],
      "metadata": {
        "id": "bWGpUcPsN3-G"
      },
      "id": "bWGpUcPsN3-G"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "metadata": {
        "id": "y9XEU1PPNloo"
      },
      "id": "y9XEU1PPNloo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Dimensionality Reduction Technique**"
      ],
      "metadata": {
        "id": "T6nW9pnIOPKa"
      },
      "id": "T6nW9pnIOPKa"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "p4pwk3VXLELT"
      },
      "id": "p4pwk3VXLELT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Encoder**"
      ],
      "metadata": {
        "id": "u36lxHgCeWsH"
      },
      "id": "u36lxHgCeWsH"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "XrDkSbQ6eZJG"
      },
      "id": "XrDkSbQ6eZJG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Time-Series**"
      ],
      "metadata": {
        "id": "_-x9Oqu_lhbE"
      },
      "id": "_-x9Oqu_lhbE"
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from fbprophet import Prophet"
      ],
      "metadata": {
        "id": "AoR24ExGLB_h"
      },
      "id": "AoR24ExGLB_h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Clustering**"
      ],
      "metadata": {
        "id": "zmQm3oo4nGMN"
      },
      "id": "zmQm3oo4nGMN"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "HgorvSwAm9br"
      },
      "id": "HgorvSwAm9br",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Transfer**"
      ],
      "metadata": {
        "id": "Ec-3UJfqnrZU"
      },
      "id": "Ec-3UJfqnrZU"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "1NWfOlfMnmzq"
      },
      "id": "1NWfOlfMnmzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Object Orientation**"
      ],
      "metadata": {
        "id": "GaAQwz4Qnmkx"
      },
      "id": "GaAQwz4Qnmkx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Object-oriented to work with files\n",
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "EWzyC2r_nl3p"
      },
      "id": "EWzyC2r_nl3p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Imputation**"
      ],
      "metadata": {
        "id": "m2zdbuGC0EwJ"
      },
      "id": "m2zdbuGC0EwJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation transformer for completing missing values\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "riIRGxunu8Ey"
      },
      "id": "riIRGxunu8Ey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Spark**"
      ],
      "metadata": {
        "id": "YQN-vqVp1f_3"
      },
      "id": "YQN-vqVp1f_3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Connection to Spark Cluster\n",
        "from pyspark import SparkContext"
      ],
      "metadata": {
        "id": "A7KIlUOt0Zpg"
      },
      "id": "A7KIlUOt0Zpg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Polynomial Feature** "
      ],
      "metadata": {
        "id": "OWAoB57K1KyP"
      },
      "id": "OWAoB57K1KyP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate polynomial and interaction features\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "oVeJzgGL1GQh"
      },
      "id": "oVeJzgGL1GQh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Image Editing**"
      ],
      "metadata": {
        "id": "lEz2ODsY1F2I"
      },
      "id": "lEz2ODsY1F2I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide python interpreter to edit image\n",
        "from PIL to import Image"
      ],
      "metadata": {
        "id": "oIEnVa8p1Flm"
      },
      "id": "oIEnVa8p1Flm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "AhlNyBD3CiIN",
      "metadata": {
        "id": "AhlNyBD3CiIN"
      },
      "source": [
        "# **2. Prep Your Customized Library Block Beforehand**\n",
        "\n",
        "**Pro** - Customization! If you don't like the magic one line of code of 115 keys pre-import. Or you don't believe what they claimed to cover your 99% of daily work. It's still worthy to prep in advance for the customized library block beforehand. \n",
        "\n",
        "**Con** - It absolutely takes some time to generate a complete full one block beforehand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7eafa2",
      "metadata": {
        "id": "ea7eafa2"
      },
      "outputs": [],
      "source": [
        "# Top Basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# All the classifiers and regressors in need\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Report and confusion matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7hG0J7uudr9X",
      "metadata": {
        "id": "7hG0J7uudr9X"
      },
      "source": [
        "# **3. Import Libraries On Demand**\n",
        "\n",
        "**Pro** - In Hackathon, you have a lot of teamworks between or among your teammates. They may work on different mini projects in paralell. It's always worhty to ask for everyone prepare their own libraries on demand to full fill local blocks usage - It's better for copy and paste moving around the module-concept in this big project without losing necearry libraries. Again, there are many libraries not covered yet in pyforest\n",
        "\n",
        "**Con** - Of course the duplicate among the teammates happens all the time. Everyone has various habit for naming."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 1: csv**\n",
        "\n",
        "In Hackathon, When you are preparing submission file in csv, it's crurical to import csv. And it's not covered by pyforest yet. Import your library on demand."
      ],
      "metadata": {
        "id": "uvdAmPIw-Vds"
      },
      "id": "uvdAmPIw-Vds"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fj4b1CTUdrG",
      "metadata": {
        "id": "3fj4b1CTUdrG"
      },
      "outputs": [],
      "source": [
        "# Prepare submission file\n",
        "import csv\n",
        "header = ['ID', 'Overall_Experience']\n",
        "with open('Submission_RF.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(zip(merged_test_df.ID,final_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Example 2: tensorflow and keras**\n",
        "\n",
        "In Hackathon, When you are using CNN/ANN, it's crurical to import tensorflow and keras. And it's not covered by pyforest yet. Import your library on demand."
      ],
      "metadata": {
        "id": "fU6n-H3e-Jpa"
      },
      "id": "fU6n-H3e-Jpa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7SH5o6E5W4I-",
      "metadata": {
        "id": "7SH5o6E5W4I-"
      },
      "outputs": [],
      "source": [
        "# Start artifical neural network model\n",
        "np.random.seed(42)\n",
        "import random\n",
        "import tensorflow as tf\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "# from keras.optimizers import SGD\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import style\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend \n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Bottomline**\n",
        "\n",
        "Pyforest could be a great defensive tool to make sure you already pre-import a good amount of the libraries with just one life of code efficiently as an option. In Hackathon it's always great to save time to focus on solving the problems "
      ],
      "metadata": {
        "id": "rT9YyYzRBr9x"
      },
      "id": "rT9YyYzRBr9x"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Hackathon 101 - How to Prepare Libraries Efficiently.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}